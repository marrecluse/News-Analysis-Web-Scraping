{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "3c8809a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dc31c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. PCMag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d6db24a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Specify the URL of the tech news site you want to scrape\n",
    "base_url1 = 'https://www.pcmag.com/'\n",
    "url = 'https://example.com/tech-news'\n",
    "\n",
    "# Send a GET request to the website\n",
    "response = requests.get(base_url1)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Create a BeautifulSoup object to parse the HTML\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find the relevant elements containing the news links and titles\n",
    "    links = soup.find_all('a', class_='font-bold text-base')\n",
    "\n",
    "    # Create a list to store the href and data_item values\n",
    "    link_data = []\n",
    "\n",
    "    # Iterate over the links and extract the href and data_item attributes\n",
    "    for link in links:\n",
    "        # Extract the href\n",
    "        href = link.get('href')\n",
    "        \n",
    "        # Append the base URL to the href using urljoin\n",
    "        full_url = urljoin(base_url, href)\n",
    "        \n",
    "        # Extract the data_item value\n",
    "        data_item = link.get('data-item')\n",
    "        \n",
    "        # Create a tuple to store the full_url and data_item\n",
    "        link_tuple = (full_url, data_item)\n",
    "        \n",
    "        # Add the link tuple to the list\n",
    "        link_data.append(link_tuple)\n",
    "\n",
    "    # Print the scraped data\n",
    "#     for link_tuple in link_data:\n",
    "#         full_url, data_item = link_tuple\n",
    "#         print('Full URL:', full_url)\n",
    "#         print('Data Item:', data_item)\n",
    "#         print('------------------------')\n",
    "else:\n",
    "    print('Failed to retrieve the web page. Status code:', response.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecff2f70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "51cf469b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. Wired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56607488",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "8c81835d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Specify the URL of the tech news site you want to scrape\n",
    "base_url2 = 'https://www.techradar.com/'\n",
    "url2 = 'https://example.com/tech-news'\n",
    "\n",
    "# Send a GET request to the website\n",
    "response2 = requests.get(base_url2)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response2.status_code == 200:\n",
    "    # Create a BeautifulSoup object to parse the HTML\n",
    "    soup2 = BeautifulSoup(response2.text, 'html.parser')\n",
    "\n",
    "    # Find the relevant elements containing the news links and titles\n",
    "    links2 = soup2.find_all('a', class_='article-link')\n",
    "\n",
    "    # Create a list to store the href and data_item values\n",
    "    link_data2 = []\n",
    "\n",
    "    # Iterate over the links and extract the href and data_item attributes\n",
    "    for link2 in links2:\n",
    "        # Extract the href\n",
    "        href2 = link2.get('href')\n",
    "        \n",
    "        # Append the base URL to the href using urljoin\n",
    "        full_url2 = urljoin(base_url2, href)\n",
    "        \n",
    "        # Extract the data_item value\n",
    "        data_item2 = link2.get('aria-label')\n",
    "        \n",
    "        # Create a tuple to store the full_url and data_item\n",
    "        link_tuple2 = (full_url2, data_item2)\n",
    "        \n",
    "        # Add the link tuple to the list\n",
    "        link_data2.append(link_tuple)\n",
    "\n",
    "    # Print the scraped data\n",
    "#     for link_tuple in link_data:\n",
    "#         full_url, data_item = link_tuple\n",
    "#         print('Full URL:', full_url)\n",
    "#         print('Data Item:', data_item)\n",
    "#         print('------------------------')\n",
    "else:\n",
    "    print('Failed to retrieve the web page. Status code:', response.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b925b372",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a1e207ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3. CNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54455c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "<a class=\"o-linkOverlay\" href=\"/tech/services-and-software/google-launches-new-ai-search-engine-how-to-sign-up/\">Google Launches New AI Search Engine: How to Sign Up</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2476025a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "3553057b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Specify the URL of the tech news site you want to scrape\n",
    "base_url3 = 'https://www.cnet.com/tech/'\n",
    "url3 = 'https://example.com/tech-news'\n",
    "\n",
    "# Send a GET request to the website\n",
    "response3 = requests.get(base_url3)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response3.status_code == 200:\n",
    "    # Create a BeautifulSoup object to parse the HTML\n",
    "    soup3 = BeautifulSoup(response3.text, 'html.parser')\n",
    "\n",
    "    # Find the relevant elements containing the news links and titles\n",
    "    links3 = soup3.find_all('a', class_='o-linkOverlay')[:10]\n",
    "\n",
    "    # Create a list to store the href and data_item values\n",
    "    link_data3 = []\n",
    "\n",
    "    # Iterate over the links and extract the href and data_item attributes\n",
    "    for link3 in links3:\n",
    "        # Extract the href\n",
    "        href3 = link3.get('href')\n",
    "        \n",
    "        # Append the base URL to the href using urljoin\n",
    "        full_url3 = urljoin(base_url3, href3)\n",
    "        \n",
    "        # Extract the data_item value\n",
    "        #data_item3 = link3.get('aria-label')\n",
    "        \n",
    "        for link_ in links3:\n",
    "            data_item3 = link_.get_text()     \n",
    "        \n",
    "        # Create a tuple to store the full_url and data_item\n",
    "        link_tuple3 = (full_url3, data_item3)\n",
    "        \n",
    "        # Add the link tuple to the list\n",
    "        link_data3.append(link_tuple3)\n",
    "\n",
    "    # Print the scraped data\n",
    "#     for link_tuple in link_data:\n",
    "#         full_url, data_item = link_tuple\n",
    "#         print('Full URL:', full_url)\n",
    "#         print('Data Item:', data_item)\n",
    "#         print('------------------------')\n",
    "else:\n",
    "    print('Failed to retrieve the web page. Status code:', response.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b249fcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "a6033cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Specify the URL of the tech news site you want to scrape\n",
    "base_url3 = 'https://www.cnet.com/tech/'\n",
    "url3 = 'https://example.com/tech-news'\n",
    "\n",
    "# Send a GET request to the website\n",
    "response3 = requests.get(base_url3)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response3.status_code == 200:\n",
    "    # Create a BeautifulSoup object to parse the HTML\n",
    "    soup3 = BeautifulSoup(response3.text, 'html.parser')\n",
    "\n",
    "    # Find the relevant elements containing the news links and titles\n",
    "    links3 = soup3.find_all('a', class_='o-linkOverlay')[:10]\n",
    "    data_item3 = [link_.get_text(strip=True) for link_ in links3]\n",
    "    \n",
    "    # Create a list to store the href and data_item values\n",
    "    \n",
    "\n",
    "    # Iterate over the links and extract the href and data_item attributes\n",
    "    link_data3=[]\n",
    "    href3 = [link.get('href') for link in links3]\n",
    "    data_item3 = [link.get_text(strip=True) for link in links3]\n",
    "    for link3 in links3:\n",
    "        # Extract the href\n",
    "#         href3 = link3.get('href')\n",
    "        full_url3 = urljoin(base_url3, href3)\n",
    "        link_tuple3 = (full_url3, data_item3)\n",
    "        link_data3.append(link_tuple3)\n",
    "\n",
    "    # Print the scraped data\n",
    "#     for link_tuple in link_data:\n",
    "#         full_url, data_item = link_tuple\n",
    "#         print('Full URL:', full_url)\n",
    "#         print('Data Item:', data_item)\n",
    "#         print('------------------------')\n",
    "else:\n",
    "    print('Failed to retrieve the web page. Status code:', response.status_code)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "7bcc8e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tech/mobile/pixel-7a-vs-galaxy-a54-pixel-6a-which-should-you-buy/'"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "href3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "2ecf1a65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"o-linkOverlay\" href=\"/tech/mobile/apple-wwdc-2023-everything-we-expect-at-the-june-5-event/\">Apple WWDC 2023: Everything We Expect at the June 5 Event</a>,\n",
       " <a class=\"o-linkOverlay\" href=\"/tech/services-and-software/use-cnet-shopping-to-seek-out-the-best-deals/\">CNET's Free Shopping Extension Saves You Time and Money. Give It a Try Today</a>,\n",
       " <a class=\"o-linkOverlay\" href=\"/tech/gaming/sony-project-q-ps5-game-handheld-revealed-what-we-know-so-far/\">Sony's Project Q PS5 Game Handheld Revealed: What We Know So Far</a>,\n",
       " <a class=\"o-linkOverlay\" href=\"/tech/services-and-software/use-cnet-shopping-to-seek-out-the-best-deals/\">CNET's Free Shopping Extension Saves You Time and Money. Give It a Try Today</a>,\n",
       " <a class=\"o-linkOverlay\" href=\"/tech/services-and-software/google-launches-new-ai-search-engine-how-to-sign-up/\">Google Launches New AI Search Engine: How to Sign Up</a>,\n",
       " <a class=\"o-linkOverlay\" href=\"/tech/mobile/apple-wwdc-2023-everything-we-expect-at-the-june-5-event/\">Apple WWDC 2023: Everything We Expect at the June 5 Event</a>,\n",
       " <a class=\"o-linkOverlay\" href=\"/tech/services-and-software/ios-16-5-the-new-features-to-land-on-your-iphone/\">iOS 16.5: The New Features to Land on Your iPhone</a>,\n",
       " <a class=\"o-linkOverlay\" href=\"/tech/services-and-software/netflix-password-sharing-is-no-longer-free-in-the-us-what-to-know/\">Netflix Password-Sharing Crackdown: What This Means for You</a>,\n",
       " <a class=\"o-linkOverlay\" href=\"/tech/gaming/sony-project-q-ps5-game-handheld-revealed-what-we-know-so-far/\">Sony's Project Q PS5 Game Handheld Revealed: What We Know So Far</a>,\n",
       " <a class=\"o-linkOverlay\" href=\"/tech/mobile/pixel-7a-vs-galaxy-a54-pixel-6a-which-should-you-buy/\">Pixel 7A vs. Galaxy A54, Pixel 6A: Which Should You Buy?</a>]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "e2eb8a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "hrefs3 = [link.get('href') for link in links3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "2428e793",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hrefs3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "9f39cb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_texts3 = [link.get_text(strip=True) for link in links3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "af4ff4bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Apple WWDC 2023: Everything We Expect at the June 5 Event',\n",
       " \"CNET's Free Shopping Extension Saves You Time and Money. Give It a Try Today\",\n",
       " \"Sony's Project Q PS5 Game Handheld Revealed: What We Know So Far\",\n",
       " \"CNET's Free Shopping Extension Saves You Time and Money. Give It a Try Today\",\n",
       " 'Google Launches New AI Search Engine: How to Sign Up',\n",
       " 'Apple WWDC 2023: Everything We Expect at the June 5 Event',\n",
       " 'iOS 16.5: The New Features to Land on Your iPhone',\n",
       " 'Netflix Password-Sharing Crackdown: What This Means for You',\n",
       " \"Sony's Project Q PS5 Game Handheld Revealed: What We Know So Far\",\n",
       " 'Pixel 7A vs. Galaxy A54, Pixel 6A: Which Should You Buy?']"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link_texts3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1349035",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "8562ed63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tech/mobile/pixel-7a-vs-galaxy-a54-pixel-6a-which-should-you-buy/'"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "href3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a28034",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5daa1107",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b7ef8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dd989a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679bfe3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba61d68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0899efaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565f4ae6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a2a31c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "# from urllib.parse import urljoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "41d46758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pcmag_url =\"https://www.pcmag.com/\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #wired\n",
    "# #pcMag\n",
    "# #forbes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ea281581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r=requests.get(pcmag_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "586d02a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# htmlContent=r.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "11745e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup=BeautifulSoup(htmlContent,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "890d4aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# links = soup.find_all('a',class_=\"font-bold text-base\")\n",
    "# print(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6bb050e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(htmlContent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "bb63547e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parsing the html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2baf9007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# links=list(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "817124ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(links[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c89577da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# link_data=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d9832d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for links in link_data:\n",
    "#     titles=links['data-item']\n",
    "#     href=links['href']\n",
    "#     link_tuple(titles,href)\n",
    "#     link_data.append(link_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "43897f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for link_tuple in link_data:\n",
    "#     titles,href=link_tuple\n",
    "# #     print('titles',titles)\n",
    "#     print('href',href)\n",
    "#     print('------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f1b4c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac039ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cca660",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc365df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d41cc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b75392c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a363b962",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1598f315",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a20422",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762c2363",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689fdc5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a6cd9757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(soup.prettify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "35147c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# title=soup.nav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "77e2844b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d9f8cc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paras=soup.find('p',class_=\"mt-2\").get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "35e8b5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(paras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8fd2f907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# for i in range(10):\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f06da6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# anchors=soup.find('a',class_=\"font-bold text-base\")\n",
    "# all_links=set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "05a8911e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(all_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb5e139",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "eb19d069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for link in anchors:\n",
    "#     if(link != '#'):\n",
    "#         linkText=\"https://codewithharry.com\" +link.get('href')\n",
    "#         all_links.add(link)\n",
    "#         print(linkText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3931cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
